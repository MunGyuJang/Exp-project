{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee08a990",
   "metadata": {},
   "source": [
    "(1) load_digits : 손글씨를 분류해 봅시다 \n",
    "====\n",
    "\n",
    "-------\n",
    "__(1) 필요한 모듈 import하기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1df76bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acefc31",
   "metadata": {},
   "source": [
    "> scikit-learn에서 제공하는 손글씨 데이터를 준비합니다.  \n",
    "알고리즘을 훈련시키기 위해 훈련용 데이터를 나눠주는 train_test_split을 import  \n",
    "알고리즘의 정확도를 파악해주는 classification_report를 import\n",
    "- - -\n",
    "__(2) 데이터 준비__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e1c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb7d230",
   "metadata": {},
   "source": [
    "> load_digits 메서드로 불러온 손글씨 데이터를 digits에 저장합니다.\n",
    "- - -\n",
    "__(3) 데이터 이해하기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7c257a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d9946e",
   "metadata": {},
   "source": [
    "> digits에는 data, target, frame, feature_names, target_names, images, DESCR 등이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15ca0f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d16812f",
   "metadata": {},
   "source": [
    "> digits의 데이터는 64개의 속성을 가진 1797개의 인스턴스가 있다고 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a65f6a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da870847",
   "metadata": {},
   "source": [
    "> DESCR의 정보에 의하면 손글씨로 쓴 10가지의 8＊8 픽셀 이미지가 포함되어 있다는걸 알 수 있습니다.  \n",
    "DESCR은 Describe을 뜻합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f829e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(digits.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49056577",
   "metadata": {},
   "source": [
    "> target_names를 보면 그 10가지의 숫자는 0부터 9까지의 숫자라는 것도 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efe45dd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data = [[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "label = [0 1 2 ... 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "X = digits.data\n",
    "y = digits.target\n",
    "print('data = {}'.format(X), 'label = {}'.format(y), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74f2a60",
   "metadata": {},
   "source": [
    "> data와 target을 각각 X와 y에 할당했습니다.\n",
    "- - -\n",
    "__(4) train, test 데이터 분리__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98531039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 64)\n",
      "(360, 64)\n",
      "(1437,)\n",
      "(360,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acc7230",
   "metadata": {},
   "source": [
    "> scikit-learn에서 데이터를 분류해주는 train_test_split 모듈을 준비해줍니다.  \n",
    "> 순서대로 특성 행렬, 타겟 벡터, 훈련 후 예측해볼 데이터 비율, 랜덤으로 섞을 때 사용할 seed를 뜻합니다.  \n",
    "   \n",
    "- 언패킹한 이름 중 X는 알고리즘이 참고할 특성 데이터. 즉 문제지라고 볼 수 있고, y는 그 답안지입니다.    \n",
    "      \n",
    "- train은 알고리즘이 훈련하는 데에 쓰일 **학습용 데이터**, test는 훈련을 한 알고리즘이 풀어볼 **테스트용 데이터**입니다.  \n",
    "  이 둘을 나누는 이유는 알고리즘이 학습한 내용을 그대로 문제로 내면 정답을 기억하고 있기 때문입니다.  \n",
    "\n",
    "- test_size를 0.2로 지정했으니 80%의 데이터를 학습하는 데에 쓰고, 20%의 데이터로 테스트를 하게 됩니다.\n",
    "\n",
    "- random_state 시드 11을 기준으로 데이터를 무작위로 섞습니다.  \n",
    "  데이터의 타켓 벡터가 정렬이 되어있으면 원활한 학습이 이루어지지 않을 수 있기 때문입니다.\n",
    "- - -\n",
    "__(5) 다양한 모델로 학습시켜보기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d409df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6daa37",
   "metadata": {},
   "source": [
    "> scikit-learn에서 알고리즘의 정확도를 측정해줄 라이브러리를 가져옵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6514a45d",
   "metadata": {},
   "source": [
    "- - -\n",
    "*Decision Tree*\n",
    "\n",
    "- 데이터 내에 존재하는 패턴을 예측 가능한 규칙들의 조합들로 나타내는 알고리즘입니다.\n",
    "- 패턴마다 뻗어나가는 규칙의 모습이 나무의 나뭇가지와 닮아서 '의사결정나무'라는 이름으로 불리게 되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "635fac24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93        35\n",
      "           1       0.84      0.84      0.84        37\n",
      "           2       0.85      0.92      0.88        36\n",
      "           3       0.78      0.84      0.81        38\n",
      "           4       0.80      0.82      0.81        40\n",
      "           5       0.96      0.81      0.88        32\n",
      "           6       0.97      0.94      0.95        31\n",
      "           7       0.81      0.91      0.85        32\n",
      "           8       0.85      0.72      0.78        40\n",
      "           9       0.81      0.77      0.79        39\n",
      "\n",
      "    accuracy                           0.85       360\n",
      "   macro avg       0.86      0.85      0.85       360\n",
      "weighted avg       0.85      0.85      0.85       360\n",
      "\n",
      "0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=15)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a50fa6",
   "metadata": {},
   "source": [
    "> Decision Tree의 경우 precision과 recall간의 큰 차이가 없고,  \n",
    "  숫자마다 최대 95%부터 최소 78%까지 정확도가 예측 결과가 다소 편파적인 모습을 보여줍니다.  \n",
    "  360개의 데이터를 예측했고 총 85%의 일치율을 보였습니다.  \n",
    "\n",
    "-  .fit 메서드를 통해 인자로 받은 학습용 문제지와 답안지를 가지고 학습을 시작합니다.  \n",
    "-  .predict 메서드를 통해 인자로 받은 테스트용 문제지를 가지고 예측한 정답을 y_pred에 저장합니다.  \n",
    "-  y_pred를 미리 저장한 y_test 답안지와 비교해 metrics에서 가져온 모듈로 일치율을 확인합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe254279",
   "metadata": {},
   "source": [
    "- - -\n",
    "*Random Forest*\n",
    "- 데이터가 가지고 있는 패턴을 랜덤으로 일부만 추출해 각각의 의사결정나무를 만들고  \n",
    "  여러 의사결정나무에서 나온 예측 값들 중 가장 많이 나온 값을 최종 예측 결과로 지정합니다.\n",
    "- 여러 개의 작은 의사결정나무를 만들어 모았다고 해서 숲이라는 이름을 가지게 되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0412ea31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        39\n",
      "           1       1.00      1.00      1.00        37\n",
      "           2       1.00      1.00      1.00        39\n",
      "           3       0.90      1.00      0.95        37\n",
      "           4       0.98      1.00      0.99        40\n",
      "           5       1.00      0.93      0.96        29\n",
      "           6       0.97      1.00      0.98        29\n",
      "           7       0.97      0.90      0.93        39\n",
      "           8       0.97      0.94      0.96        35\n",
      "           9       0.95      0.97      0.96        36\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090aa054",
   "metadata": {},
   "source": [
    "> Random Forest의 경우 마찬가지로 precision과 recall간의 큰 차이가 없고,  \n",
    "  전체적으로 높은 일치율을 보여줍니다.  \n",
    "  360개의 데이터 중 약 97.2%를 예측에 성공했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b41416f",
   "metadata": {},
   "source": [
    "- - -\n",
    "*SVM*\n",
    "- SVM은 서포트 벡터와 초평면을 이용해서 분류를 수행하는 선형 분류 알고리즘입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00b1c53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        38\n",
      "           1       1.00      1.00      1.00        37\n",
      "           2       1.00      1.00      1.00        39\n",
      "           3       0.93      1.00      0.96        38\n",
      "           4       1.00      1.00      1.00        41\n",
      "           5       1.00      0.96      0.98        28\n",
      "           6       1.00      1.00      1.00        30\n",
      "           7       0.97      0.95      0.96        37\n",
      "           8       1.00      0.97      0.99        35\n",
      "           9       0.97      0.97      0.97        37\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "0.9861111111111112\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19233c77",
   "metadata": {},
   "source": [
    "> SVM의 경우 손글씨 데이터에 대해 상당히 정확한 예측값을 추출했습니다.  \n",
    "  360개의 데이터를 예측해 약 98.6%의 일치율을 보였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dfa7cd",
   "metadata": {},
   "source": [
    "- - -\n",
    "*SGD Classifier*\n",
    "- SGD란 배치 크기가 1인 경사하강법 알고리즘입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "354e1345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        37\n",
      "           1       1.00      0.86      0.92        43\n",
      "           2       0.97      1.00      0.99        38\n",
      "           3       0.93      1.00      0.96        38\n",
      "           4       0.98      0.98      0.98        41\n",
      "           5       1.00      0.90      0.95        30\n",
      "           6       0.97      1.00      0.98        29\n",
      "           7       0.94      0.92      0.93        37\n",
      "           8       0.94      1.00      0.97        32\n",
      "           9       0.92      0.97      0.94        35\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n",
      "0.9611111111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55438428",
   "metadata": {},
   "source": [
    "> SGD Classifier의 경우 숫자 1에 대한 recall값. 즉, 1인데 1이 아니라고 하는 예측을 제외하면  \n",
    "  360개의 데이터를 예측해 약 96.1%라는 전체적으로 높은 일치율을 보였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a67a27",
   "metadata": {},
   "source": [
    "- - -\n",
    "*Logistic Regression*\n",
    "- Logistic Regression은 소프트맥스 함수를 이용한 다중 클래스 분류 알고리즘입니다.\n",
    "- 소프트맥스 회귀라고도 부르며, 이름은 회귀지만 실제로는 분류를 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0801cd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        38\n",
      "           1       0.95      1.00      0.97        35\n",
      "           2       1.00      1.00      1.00        39\n",
      "           3       0.93      1.00      0.96        38\n",
      "           4       0.98      1.00      0.99        40\n",
      "           5       1.00      0.93      0.96        29\n",
      "           6       0.97      1.00      0.98        29\n",
      "           7       0.97      0.95      0.96        37\n",
      "           8       0.91      0.84      0.87        37\n",
      "           9       0.97      0.95      0.96        38\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533932b6",
   "metadata": {},
   "source": [
    "> 총 번호 반복 횟수가 한계치에 도달했다는 오류 문구가 출력되지만  \n",
    "  알고리즘은 잘 작동한 듯 합니다.  \n",
    "  360개의 데이터를 예측해 약 96.6%로 정확도는 높지만 숫자 8에 대해 비교적 낮은 일치율을 보였습니다.\n",
    ">>만일 이보다 더 많은 데이터를 가지고 실행하려고 한다면  \n",
    "  LogisticRegression() 메서드 안에 max_iter인자를 넣고 반복 횟수 한계치를 입력하면 됩니다.  \n",
    ">>  - ex) ```logistic_model = LogisticRegression(max_iter=5000)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c01497",
   "metadata": {},
   "source": [
    "- - -\n",
    "__(6) 모델을 평가해 보기__  \n",
    "\n",
    "    손글씨 데이터에 대해 가장 높은 정확도를 보여준 알고리즘은  \n",
    "    SVM 알고리즘으로 약 98%의 일치율을 보였습니다.  \n",
    "    반대로 가장 낮은 85%의 정확도를 보여준 Decision Tree를 제외하면  \n",
    "    나머지 Random Forest, SGD Classifier, Logistic Regression 모두 안정적인 정확도를 보여줬습니다.  \n",
    "    손글씨와 같은 각각 비슷한 특성을 가진 데이터를 분류할 때 Decision Tree 알고리즘은 사용을 피해야겠습니다.  \n",
    "\n",
    "\n",
    "-----\n",
    "(2) load_wine : 와인을 분류해 봅시다\n",
    "====\n",
    "\n",
    "-------\n",
    "__(1) 필요한 모듈 import하기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b756eab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e98ff4",
   "metadata": {},
   "source": [
    "> scikit-learn에서 제공하는 와인 데이터를 준비합니다.\n",
    "- - -\n",
    "__(2) 데이터 준비__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b1c4511",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d1ee30",
   "metadata": {},
   "source": [
    "> load_wine 메서드로 불러온 와인 데이터를 wine에 저장합니다.\n",
    "- - -\n",
    "__(3) 데이터 이해하기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1149f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39be04e",
   "metadata": {},
   "source": [
    "> wine에는 data, target, frame, target_names, DESCR, feature_names 등이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17ed6439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6fa81c",
   "metadata": {},
   "source": [
    "> wine의 데이터는 13개의 속성을 가진 178개의 인스턴스가 있다고 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4996c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(wine.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c9e294",
   "metadata": {},
   "source": [
    "> DESCR에 의하면 와인에는 알코올, 사과산, 애쉬 함유되어 등이 있고, 와인마다 클래스0, 클래스1, 클래스2로 분류가 되어있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c4e532a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "print(wine.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce64df9",
   "metadata": {},
   "source": [
    "> 알고리즘이 분류할 클래스입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93ac42ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data = [[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
      " ...\n",
      " [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
      " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
      " [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n",
      "label = [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "X = wine.data\n",
    "y = wine.target\n",
    "print('data = {}'.format(X), 'label = {}'.format(y), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94908d7",
   "metadata": {},
   "source": [
    "> data와 target을 각각 X와 y에 할당을 했지만  \n",
    "  data의 모습이 뭔가 이상합니다.  \n",
    "  wine.data의 타입을 먼저 살펴봐야겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0340e670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(wine.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546a9c2d",
   "metadata": {},
   "source": [
    "> array 타입입니다. wine.data를 확인하려면 pandas를 이용해야겠군요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e16b964a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "0                            3.92   1065.0  \n",
       "1                            3.40   1050.0  \n",
       "2                            3.17   1185.0  \n",
       "3                            3.45   1480.0  \n",
       "4                            2.93    735.0  \n",
       "..                            ...      ...  \n",
       "173                          1.74    740.0  \n",
       "174                          1.56    750.0  \n",
       "175                          1.56    835.0  \n",
       "176                          1.62    840.0  \n",
       "177                          1.60    560.0  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "wine_df = pd.DataFrame(data=wine.data, columns=wine.feature_names)\n",
    "wine_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e4f5fd",
   "metadata": {},
   "source": [
    "- - -\n",
    "__(4) train, test 데이터 분리__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0fb24ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 13)\n",
      "(36, 13)\n",
      "(142,)\n",
      "(36,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ae580d",
   "metadata": {},
   "source": [
    "> 이번에도 학습용 데이터와 테스트용 데이터를 분류해줍니다.  \n",
    "  train_test_split은 이미 손글씨를 분석하면서 불러온 바 있으나  \n",
    "  모듈과 좀 더 친근해지기 위해 한 번 더 불러왔습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447a2a79",
   "metadata": {},
   "source": [
    "- - -\n",
    "__(5) 다양한 모델로 학습시켜보기)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e296493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507b3763",
   "metadata": {},
   "source": [
    "> metrics 패키지의 정확도 표현 모듈도 다시 한 번 불러와줍니다.  \n",
    "  ~~사실 프로젝트 파일을 열 때마다 불러와야 하기도 해서 다시 import 코드를 작성해줍시다.~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03838f8",
   "metadata": {},
   "source": [
    "- - -\n",
    "*Decision Tree*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc2bf040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.87        13\n",
      "           1       1.00      0.73      0.85        15\n",
      "           2       0.88      0.88      0.88         8\n",
      "\n",
      "    accuracy                           0.86        36\n",
      "   macro avg       0.88      0.87      0.86        36\n",
      "weighted avg       0.89      0.86      0.86        36\n",
      "\n",
      "0.8611111111111112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=14)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ab12ac",
   "metadata": {},
   "source": [
    "> 클래스0의 precision, 클래스1의 recall에 특히 낮은 정확도를 보여줍니다.  \n",
    "  클래스0이 아닌데 클래스0이라고 하고, 클래스1인데 클래스1이 아니라고 하는 것을 보아  \n",
    "  클래스1을 클래스0으로 잘못 판정한 경우가 많은 듯 보입니다.  \n",
    "  36개의 데이터를 예측해 약 86.1%의 일치율을 보였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00f6624",
   "metadata": {},
   "source": [
    "- - -\n",
    "*Random Forest*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd97f320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.92      0.96        12\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.97      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=24)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10d90c9",
   "metadata": {},
   "source": [
    "> 역시 나무보다는 숲이 분석에 있어 더 강한 모습을 보입니다.  \n",
    "  36개의 데이터를 예측해 약 97.2%의 일치율을 보였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a5406b",
   "metadata": {},
   "source": [
    "- - -\n",
    "*SVM*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07433240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.77        14\n",
      "           1       0.82      0.69      0.75        13\n",
      "           2       0.50      0.44      0.47         9\n",
      "\n",
      "    accuracy                           0.69        36\n",
      "   macro avg       0.67      0.66      0.66        36\n",
      "weighted avg       0.69      0.69      0.69        36\n",
      "\n",
      "0.6944444444444444\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa43fa9",
   "metadata": {},
   "source": [
    "> 손글씨 데이터를 분석했을 때와는 정반대로  \n",
    "  전체적으로 낮은 정확도를 보여줍니다.  \n",
    "  36개의 데이터를 예측해 약 69.4%의 일치율을 보였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76f2bd4",
   "metadata": {},
   "source": [
    "- - -\n",
    "*SGD Classifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9aa7643e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.71        11\n",
      "           1       0.45      0.71      0.56         7\n",
      "           2       0.75      0.33      0.46        18\n",
      "\n",
      "    accuracy                           0.58        36\n",
      "   macro avg       0.60      0.65      0.58        36\n",
      "weighted avg       0.64      0.58      0.56        36\n",
      "\n",
      "0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811932c7",
   "metadata": {},
   "source": [
    "> SGD Classifier 또한 와인 데이터를 분석하는 데에 취약한 모습을 보입니다.  \n",
    "  36개의 데이터를 예측해 약 58.3%의 일치율을 보였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d977c5",
   "metadata": {},
   "source": [
    "- - -\n",
    "*Logistic Regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "80a96a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.85      0.92        13\n",
      "           2       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.94      0.95      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=5000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0216bf",
   "metadata": {},
   "source": [
    "> 소프트맥스 함수는 와인 데이터를 분석하는 데에도 비교적 높은 정확도를 보여줍니다.  \n",
    "  36개의 데이터를 예측해 약 94.4%의 일치율을 보였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8ed5aa",
   "metadata": {},
   "source": [
    "- - -\n",
    "__(6) 모델을 평가해 보기__  \n",
    "\n",
    "    와인 데이터에 대해 가장 높은 정확도를 보여준 알고리즘은  \n",
    "    Random Forest 알고리즘으로 약 97%의 일치율을 보였습니다.  \n",
    "    반면 손글씨 데이터에서 높은 정확도를 보여줬던 SVM과 SGD Classifier 알고리즘은  \n",
    "    오히려 와인 데이터를 분석하기엔 적합하지 않은 모습을 보여줬습니다.  \n",
    "    데이터를 분류할 때 다양한 특성이 고려되어야 한다면 Random Forest 알고리즘을 채택하는 것이 바람직해 보입니다.\n",
    "\n",
    "\n",
    "-----\n",
    "(3) load_breast_cancer : 유방암 여부를 진단해 봅시다\n",
    "====\n",
    "\n",
    "-------\n",
    "__(1) 필요한 모듈 import하기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "20e038c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f208ad5c",
   "metadata": {},
   "source": [
    "> scikit-learn에서 제공하는 유방암 데이터를 준비합니다.\n",
    "- - -\n",
    "__(2) 데이터 준비__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c0d4045",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bd4bad",
   "metadata": {},
   "source": [
    "> load_breast_cancer 메서드로 불러온 유방암 데이터를 breast_cancer에 저장합니다.\n",
    "- - -\n",
    "__(3) 데이터 이해하기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "be57ed95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e167839c",
   "metadata": {},
   "source": [
    "> breast_cancer에는 data, target, frame, target_names, DESCR, feature_names, filename, data_module 등이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "74182cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f2c890",
   "metadata": {},
   "source": [
    "> breast_cancer.data는 30개의 속성을 가진 569개의 인스턴스가 있다고 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3d7c6f23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(breast_cancer.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aa9779",
   "metadata": {},
   "source": [
    "> DESCR을 보니 데이터에 대한 설명이 너무 많아 저희는 특성에 대한 정보를 위주로 확인해봐야겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a88e76a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "print(breast_cancer.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b331a3",
   "metadata": {},
   "source": [
    "> 특성들로 평균 반경, 평균 텍스쳐, 평균 둘레, 평균 면적, ...최악의 대칭, 최악의 프랙탈 디멘션 등등을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5a970d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "print(breast_cancer.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e29c40",
   "metadata": {},
   "source": [
    "> 알고리즘은 유방암 특성 데이터를 분석해 악성인지 양성인지를 판단하게 될 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aca01426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data = [[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n",
      "label = [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "print('data = {}'.format(X), 'label = {}'.format(y), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffec2890",
   "metadata": {},
   "source": [
    "> 이번에도 breast_cancer.data가 array 형식인 듯 합니다.  \n",
    "  확인을 위해서 pandas를 이용합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3013c123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_df = pd.DataFrame(data=breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "breast_cancer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725cfcc0",
   "metadata": {},
   "source": [
    "- - -\n",
    "__(4) train, test 데이터 분리__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "77682dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30)\n",
      "(114, 30)\n",
      "(455,)\n",
      "(114,)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=29)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cbbe73",
   "metadata": {},
   "source": [
    "- - -\n",
    "__(5) 다양한 모델로 학습시켜보기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cca8188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8737565b",
   "metadata": {},
   "source": [
    "> 불러왔던 모듈을 매번 import로 불러올 필요는 없다는 것을 확인하기 위해 이번에는 주석으로 실행을 건너뛰어 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae54c09",
   "metadata": {},
   "source": [
    "- - -\n",
    "*Decition Tree*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "48e6294d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84        37\n",
      "           1       0.93      0.91      0.92        77\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.90      0.89      0.90       114\n",
      "\n",
      "0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=33)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528cba5b",
   "metadata": {},
   "source": [
    "> 114개의 데이터를 예측해 약 89.4%의 일치율을 보였지만  \n",
    "  악성(0)인데 악성이 아니라고 판단한 recall정확도는 약 86%로  \n",
    "  결과값의 중요도에 비하면 낮은 일치율이라고 할 수 있습니다.\n",
    "- 유방암 데이터를 분석하는 데에 있어서 중요한 것은  \n",
    "  전체의 정확도보다는 혹시 양성을 음성으로 잘못 판단하지는 않았는지에 대한 recall 정확도입니다.  \n",
    "  유방암 데이터를 분석하기에 적합한 알고리즘을 선택하는 기준은 recall을 우선으로 판단하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27d079a",
   "metadata": {},
   "source": [
    "- - -\n",
    "*Random Forest*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b9320c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.91        36\n",
      "           1       0.97      0.94      0.95        78\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.92      0.94      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "0.9385964912280702\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=45)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280071fa",
   "metadata": {},
   "source": [
    "> 이번에도 여러 의사결정나무를 사용하는 Random Forest 알고리즘은 꽤 높은 정확도를 보여줍니다.  \n",
    "  114개의 데이터를 예측해 약 94%의 recall 일치율을 보였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68b82dc",
   "metadata": {},
   "source": [
    "- - -\n",
    "*SVM*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "be226752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.97      0.84        30\n",
      "           1       0.99      0.88      0.93        84\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.87      0.92      0.89       114\n",
      "weighted avg       0.92      0.90      0.91       114\n",
      "\n",
      "0.9035087719298246\n"
     ]
    }
   ],
   "source": [
    "# from sklearn import svm\n",
    "\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbec432",
   "metadata": {},
   "source": [
    "> 악성이 아닌데 악성으로 잘못 판단하는 경우와  \n",
    "  양성인데 양성이 아니라고 잘못 판단하는 경우가 많은 모습을 보입니다.  \n",
    "  114개의 데이터를 예측해 약 92%의 recall 일치율을 보였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb942fe7",
   "metadata": {},
   "source": [
    "- - -\n",
    "*SGD Classifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "88704777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      1.00      0.78        25\n",
      "           1       1.00      0.84      0.91        89\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.82      0.92      0.85       114\n",
      "weighted avg       0.92      0.88      0.89       114\n",
      "\n",
      "0.8771929824561403\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3f0f24",
   "metadata": {},
   "source": [
    "> SVM 알고리즘과 상당히 비슷한 결과가 나왔습니다.  \n",
    "  114개의 데이터를 예측해 약 92%의 recall 일치율을 보였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d11656e",
   "metadata": {},
   "source": [
    "- - -\n",
    "*Logistic Regresstion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3c319f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89        37\n",
      "           1       0.96      0.94      0.95        77\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.92      0.93      0.92       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=5000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa8c945",
   "metadata": {},
   "source": [
    "> 이번에도 Random Forest와 비슷한 결과를 도출하면서  \n",
    "  유방암 데이터를 분석하기에 역시 쓸만한 정확도를 보여줍니다.  \n",
    "  114개의 데이터를 예측해 약 93%의 recall 일치율을 보였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e183ef8c",
   "metadata": {},
   "source": [
    "- - -\n",
    "__(6) 모델을 평가해 보기__\n",
    "\n",
    "    유방암 진단과 같은 전체의 정확도보다 recall 정확도가 더 중요한 데이터의 경우에는  \n",
    "    Random Forest 알고리즘과 Logistic Regression 알고리즘이 적합한 모습을 보였습니다.  \n",
    "    다만 함수의 실행 속도를 보면 Logistic Regression 알고리즘이 더 무거운 느낌이 있었기 때문에  \n",
    "    저는 Random Forest 알고리즘을 더 선호할 것 같습니다.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
